       	       	     +-------------------------+
		     |		CS 140	       |
		     | PROJECT 4: FILE SYSTEMS |
		     |	   DESIGN DOCUMENT     |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Xiaojiang Guo <gxj@stanford.edu>
Chunyan Wang  <chunyan@stanford.edu>
Yinfeng Qin   <yinfeng@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

We changed the structure of on-disk inode, which now looks like

     ----------
    |    0     |
     ----------      ----------
    |    1     |    |    0     |
     ----------      ----------
    |    :     |    |    1     |
    |    :     |     ----------               ----------
     ----------     |    :     |             |    0     |
    |    122   |  / |    :     |              ----------
     ----------  //  ----------          === |    :     |
    |          | /  |    127   |       //    |    :     |
    | indirect |     ----------       //      ----------
    |  block   |                     //      |    127   |
    |          |        ----------  //        ----------
     ----------        |    0     | /
    |          |        ----------    :
    |  doubly  |       |    1     |
    | indirect | =====  ----------    :
    |  block   |       |    :     |           ----------
    |          |       |    :     |   :      |    0     |
     ----------         ----------            ----------
                       |    127   | ======== |    :     |
                        ----------           |    :     |
                         indirect             ----------
                          blocks             |    127   |
                                              ----------

Now each inode_disk strucutre can hold a file with maximum size of
    512 * (122 + 128 + 128 * 128) = 8,516,608 Bytes ~ 8.12MB


---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

We add a lock in inode structure preventing simultaneous expansion of the
same file. When multiple process performs an expansion on a same file (also
on the same inode structure), only one of them can proceed with the acquired
lock.


>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

The majority of the logic determining whether or not an expasion is needed
is done by byte_to_sector() and the expand_inode().

When A and B both reach the end-of-file, A would compare the desired read
position with the actual end-of-file, which may have been updated by a 
write past previous end-of-file by B.

In our code, the length of file is updated only after all allocation and
actual writing of content has finished by B. This way, either A reaches
the previous end-of-file before B updates the file length, and A would
determine there is nothing to read, and return with no content read;
or A may reach the previous end-of-file after B updates the file length,
and by this time B have already allocated and written all contents
and properly updated end-of-file, so A can safely ready the newly written
contents. In both cases, A will either read nothing or read data B writes.


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

/* TODO this paragraph seems not to be right */
The main synchronization happens at buffer cache level. We implemented
shared lock for each block in buffer cache, allowing multiple process to
read together, while providing exclusive right to write on each block in
buffer cache. However, we do not force an exclusive use of the entire file
or inode strucutre, thus allowing multiple processes to access a file at
the same time.
/*  */


---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

Our inode strucutre is a multilevel index. We choose the combination of
100 direct data blocks, together with 1 indirect block pointing to another
128 data blocks, and 1 doubly indirect block pointing to yet another
128 * 128 data blocks.

This choice of combination works well in real-life situations where most
files in a file system are small, while at the same time there are some
really large files. With our design, for most small files no larger than
100 blocks (51200 Bytes) in size, we can find their sector and perform
I/O to disk data with two disk operations. When the files are really large,
the system would have perform I/O to disk with three or four operations,
but this is the rare case and the overall expected performance is still good.


			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

To traverse a user-specified path, judgement is made using the first character
of given path to decide whether it is a relative path or absolute one. An 
absolute path starts with "/", and the directory is opened starting from root
directory. For relative paths, process's current directory is used as the
starting point. The parse and open process of given path is performed the same.


---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

To prevent the race conditions on directory entries, we implement a lock in
each inode for directory access. Since the directory's inode is the only 
thing differentiating it from other directories, a lock inside the inode 
could help us prevent multiple accesses to the same directory but allow 
different directories to be opened or modified concurrently. 

For instance, to avoid two simultaneous attempts to remove a single file, the
working directory's lock inside its inode is acquired at the beginning of the
remove process. In doing so, other remove calls working on a different 
directory could happen at the same time, while operations on one directory is 
waiting for one another. The directory's lock is released until the end of 
remove process, so that remove operation in the same directory could not simul. 
to for file system operation. Each system call for modifying or creating a new
file is only allowed to be done sequentially on system call level. It is true
that some of the parallerism may not be taken full advantage of in this case. 
But considering the fact that remove and create an directory entry may 
interleave if synchronization is implemented on directory operation level, 


>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

In our design, we disallow a directory to be removed if it is opened or in use 
by any process other than the process performing "delete".

This is because if we allow the directory to be deleted when other processses 
still working on it, each time when a process needs to perform tasks on its 
current directory, it has to check whether its current directory is still valid
, as for that its current directory could be deleted by other processes without
any notification. This would cause a lot of waste in checking. It would also 
require extra overhead in synchroniztion if deletion is allowed, since a 
deletion could happen at any point when a process is openning or working on the
directory. Efforts have to be made to prevent race conditions in this case.  We 
believe that overall performance would be hampered if such deletion is allowed.
That is why we disallow such deletion. 

To prevent the deletion of the opened directory, we added a function to check
if the directory is opened by other processes or not. As the directory's 
inode is always opened by the "delete" process for deletion, the inode's open
count would be larger than 2 if any other processes is working on it. Whenever
a deletion is executed, the open count is compared to decide whether the 
directory satifies deletion requirements. The directory's inode open count 
could be served as an effective judgement only if processes' working directory
actually opens the directory when working or openning it. This is why we 
implement a directory struct pointer in each process pointing to the opened 
directory. If a direcoty does not satisfy deletion requirments, the deletion 
would be aborted.


---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

We choose to represent the current directory of a process by using a directory
pointer to point at current directory. Each time a "chdir" system call is 
called, the old directory is closed and the directory pointer is pointed
to the new directory. A new process's current directory is inherited from
its parent process, by reopen the parent process's directory. Another way to 
record current directory is to use a string pointer record the absolute path
of the process's current directory. One major disadvantage is that, opening 
a new file requires sequentially opens all the subdirectories every time. 

Much of the time and space would enduced especially when the process's current
directory becomes deep. We choose to use the first approach to avoid this 
problem. By pointing to the current directory struct, open or create a new file
in current directory does not need to open and search through all the 
subdirectories from root. 

Another advantage to use directory pointer pointed to actual directory struct
is in the benefits of telling an directory's inode that it is currently being
used. Whenever a subdirectory is pointed by the process, a dir_open call 
would be made, which is ensued by an inode_open of the directory's inode. 
In this way, it is easier to know if other processes are pointing at the 
directory for the judgement of whether deletion of current process is 
appropriate.


			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/**/
Justify the reason we use a list to contain 64 buffer cache:
we need to visit all buffer caches to determine a block to evict anyway,
so a list is a reasonable choice to serve this aim.
/**/


---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

>> C3: Describe your implementation of write-behind.

>> C4: Describe your implementation of read-ahead.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

To prevent other processes from evicting a block that is currently under 
writing or reading, we implement a cache lock for each of the cache block. 
Different blocks share an independent lock so that concurrent operations
on different cache blocks are guaranteed. In our design, the lock has two 
modes: one is acquire_shared, which is used for multiple processes reading
the same block and prevent further writing operations; the other mode is
acquire_exclusive, which one is used for cache writing or cache evitions. In 
our design, any time before a cache becomes actively reading or writing, the
integer inside the cache lock is added, and decreased when the lock is freed. 

By doing so, we ensure that the integer inside lock is positive if any 
process is using it. We implement our design of selecting victim by ensure 
that the integer is not positive. In doing so, we ensured that the cache 
block chosen as victim is not currently in reading or in writing. And that
other processes would not evict an active data in the buffer cache block. 


>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

To assure that the victim block would not be further accessed by other block
during the process of eviction, we acquire the exclusive cache block right 
after the victim is chosen. and release the lock until the cache block's 
content is written back to disk. Since other activites such as writing or 
reading all requires to acquire the lock possessed by the eviction process,
further access to the same block is prevented during eviction.


---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

One typical file workload that is likely to benefit from buffer caching
is in our file growth procedure. This workload involves many read, update
and write back to disk the indirect and doubly indirect inodes when there 
is a huge growth. In this case, by caching the indirect and doubly indirect
inodes, the performance would be significantly improved.

A file workload that involved sequential read would benefit from read-ahead.
For example, when memory-mapping a large file spanning many block sectors,
by read-ahead, we would already have the following few blocks in cache after
the first disk read, and this saves many disk reads for the following block
reads.

A file workload that involves interleaved computing and writing would benefit
from write-behind. Without write-behind, the process would have to wait the 
disk write to finish before continuing the computing, thus wasting many CPU
cycles waiting for the disk write. With write-behind, the process can simply
write the data to buffer cache and continue with the computing, and the actual
write to disk would proceed in background when the CPU is relatively free. The
performance under this kind of workload would benefit from write-behind.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
